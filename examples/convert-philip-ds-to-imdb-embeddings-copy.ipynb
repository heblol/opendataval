{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koen/opt/anaconda3/envs/opendataval/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the opendataval folder.\n",
    "# It will now recognise all the imports correctly.\n",
    "import os \n",
    "os.chdir('/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval')\n",
    "from opendataval.dataloader.util import ListDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv(filename: str):\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eddie Murphy and Richard Pryor team up in this...</td>\n",
       "      <td>Eddie Murphy and Richard Pryor team up in this...</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.702690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a big fan of Patricia Hodge and Mariam Mar...</td>\n",
       "      <td>I'm a big fan of Patricia Hodge and Mariam Mar...</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.798640</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just to let everyone know, this is possibly th...</td>\n",
       "      <td>Just to let everyone know, this is possibly th...</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.931049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Electra Glide in Blue\" is a slow moving B-fli...</td>\n",
       "      <td>\"Electra Glide in Blue\" is a slow moving B-fli...</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.886638</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm a huge Zack Allan fan and was [[disappoint...</td>\n",
       "      <td>I'm a huge Zack Allan fan and was [[disappoUnt...</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.760442</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Eddie Murphy and Richard Pryor team up in this...   \n",
       "1  I'm a big fan of Patricia Hodge and Mariam Mar...   \n",
       "2  Just to let everyone know, this is possibly th...   \n",
       "3  \"Electra Glide in Blue\" is a slow moving B-fli...   \n",
       "4  I'm a huge Zack Allan fan and was [[disappoint...   \n",
       "\n",
       "                                      perturbed_text  original_score  \\\n",
       "0  Eddie Murphy and Richard Pryor team up in this...        0.002222   \n",
       "1  I'm a big fan of Patricia Hodge and Mariam Mar...        0.002670   \n",
       "2  Just to let everyone know, this is possibly th...        0.003340   \n",
       "3  \"Electra Glide in Blue\" is a slow moving B-fli...        0.002544   \n",
       "4  I'm a huge Zack Allan fan and was [[disappoUnt...        0.003667   \n",
       "\n",
       "   perturbed_score  original_output  perturbed_output  ground_truth_output  \\\n",
       "0         0.702690                0                 1                    0   \n",
       "1         0.798640                0                 1                    0   \n",
       "2         0.931049                0                 1                    0   \n",
       "3         0.886638                0                 1                    0   \n",
       "4         0.760442                0                 1                    0   \n",
       "\n",
       "   num_queries result_type  \n",
       "0           90  Successful  \n",
       "1          131  Successful  \n",
       "2           40  Successful  \n",
       "3           48  Successful  \n",
       "4           74  Successful  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset containing the synthetic generated UUs\n",
    "\n",
    "illuminatingUU = import_csv(\"data-imdb/uus-imdb-bert-original-dwb-uu.csv\")\n",
    "\n",
    "illuminatingUU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      perturbed_text  original_output\n",
      "0  Eddie Murphy and Richard Pryor team up in this...                0\n",
      "1  I'm a big fan of Patricia Hodge and Mariam Mar...                0\n",
      "2  Just to let everyone know, this is possibly th...                0\n",
      "3  \"Electra Glide in Blue\" is a slow moving B-fli...                0\n",
      "4  I'm a huge Zack Allan fan and was [[disappoUnt...                0\n",
      "--------------------\n",
      "original_output\n",
      "0    1682\n",
      "Name: count, dtype: int64\n",
      "--------------------\n",
      "                                      perturbed_text  original_output\n",
      "0  Eddie Murphy and Richard Pryor team up in this...                0\n",
      "1  I'm a big fan of Patricia Hodge and Mariam Mar...                0\n",
      "2  Just to let everyone know, this is possibly th...                0\n",
      "3  \"Electra Glide in Blue\" is a slow moving B-fli...                0\n",
      "4  I'm a huge Zack Allan fan and was [[disappoUnt...                0\n"
     ]
    }
   ],
   "source": [
    "# The Register expects the import \"review\", \"sentiment\"\n",
    "# \"sentiment\" = [\"positive\", \"negative\"]\n",
    "\n",
    "bert_ds = illuminatingUU[[\"perturbed_text\", \"original_output\"]]\n",
    "print(bert_ds.head())\n",
    "print(\"-\"*20)\n",
    "print(bert_ds[\"original_output\"].value_counts())\n",
    "print(\"-\"*20)\n",
    "print(bert_ds.head())\n",
    "# Question: only containing positive or negative sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       original_text  \\\n",
      "0  Eddie Murphy and Richard Pryor team up in this...   \n",
      "1  I'm a big fan of Patricia Hodge and Mariam Mar...   \n",
      "2  Just to let everyone know, this is possibly th...   \n",
      "3  \"Electra Glide in Blue\" is a slow moving B-fli...   \n",
      "4  I'm a huge Zack Allan fan and was [[disappoint...   \n",
      "\n",
      "                                      perturbed_text  original_score  \\\n",
      "0  Eddie Murphy and Richard Pryor team up in this...        0.002222   \n",
      "1  I'm a big fan of Patricia Hodge and Mariam Mar...        0.002670   \n",
      "2  Just to let everyone know, this is possibly th...        0.003340   \n",
      "3  \"Electra Glide in Blue\" is a slow moving B-fli...        0.002544   \n",
      "4  I'm a huge Zack Allan fan and was [[disappoUnt...        0.003667   \n",
      "\n",
      "   perturbed_score  original_output  perturbed_output  ground_truth_output  \\\n",
      "0         0.702690                0                 1                    0   \n",
      "1         0.798640                0                 1                    0   \n",
      "2         0.931049                0                 1                    0   \n",
      "3         0.886638                0                 1                    0   \n",
      "4         0.760442                0                 1                    0   \n",
      "\n",
      "   num_queries result_type  \n",
      "0           90  Successful  \n",
      "1          131  Successful  \n",
      "2           40  Successful  \n",
      "3           48  Successful  \n",
      "4           74  Successful  \n",
      "Index(['original_text', 'perturbed_text', 'original_score', 'perturbed_score',\n",
      "       'original_output', 'perturbed_output', 'ground_truth_output',\n",
      "       'num_queries', 'result_type'],\n",
      "      dtype='object')\n",
      "(1682, 9)\n"
     ]
    }
   ],
   "source": [
    "df = import_csv(\"data-imdb/uus-imdb-bert-original-dwb-uu.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendataval.dataloader.util import ListDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataset st BertEmbeddings can read it.\n",
    "from pyparsing import Any\n",
    "from opendataval.dataloader.util import ListDataset\n",
    "\n",
    "def get_list_for_custom_nlp_dataset(cache_dir: str = None, force_download: bool = False) -> tuple[ListDataset, np.ndarray[Any]]:\n",
    "\n",
    "    df = import_csv(\"data-imdb/hypo-llm-imdb-bert-original-dwb-gpt-generation-response-filtered-gpt-generation.csv\")\n",
    "    print(df.head())\n",
    "    print('shape=', df.shape)\n",
    "    print(\"columns\", df.columns)\n",
    "\n",
    "    # Get the text and label columns\n",
    "    df = df[[\"text\", \"label\"]]\n",
    "\n",
    "    # df = illuminatingUU[[\"text\", \"label\"]]\n",
    "\n",
    "    label_dict = {0: 0, 1: 1}\n",
    "\n",
    "    print('types:', df.dtypes)\n",
    "    print(\"-\"*10)\n",
    "    labels = np.fromiter((label_dict[label] for label in df[\"label\"]), dtype=int)\n",
    "\n",
    "    print(\"labels:\", labels)\n",
    "\n",
    "\n",
    "    return ListDataset(df[\"text\"].values), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  The cinematography in this film is absolutely ...      1\n",
      "1  The cinematography in this film was absolutely...      0\n",
      "2  I was so excited to see this new movue, but it...      0\n",
      "3  The movie, The Shawshank RedempCtion, is a cla...      1\n",
      "4  I was absolutely blown away by the stunning vi...      1\n",
      "shape= (486, 2)\n",
      "columns Index(['text', 'label'], dtype='object')\n",
      "types: text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "----------\n",
      "labels: [1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 0\n",
      " 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1\n",
      " 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1\n",
      " 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
      " 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1\n",
      " 0 1 1 1 0]\n",
      "----------start----------\n",
      "486\n",
      "486\n",
      "----------end----------\n"
     ]
    }
   ],
   "source": [
    "values, labels = get_list_for_custom_nlp_dataset()\n",
    "\n",
    "print(\"-\"*10 + \"start\" + \"-\"*10)\n",
    "print(len(values))\n",
    "print(len(labels))\n",
    "\n",
    "print(\"-\"*10 + \"end\" + \"-\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_df_as_import(df: pd.DataFrame):\n",
    "\n",
    "    return get_list_for_custom_nlp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function opendataval.dataloader.datasets.nlpsets.download_imdb_illuminating(cache_dir: str, force_download: bool)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opendataval.dataloader.register import Register\n",
    "from opendataval.dataloader.datasets.nlpsets import BertEmbeddings, download_imdb_illuminating\n",
    " \n",
    "dataset_name = \"illuminating2\"\n",
    "embedding = Register(dataset_name, True, True)(download_imdb_illuminating)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataset was imported correctly.\n",
    "from opendataval.dataloader import DataFetcher, mix_labels\n",
    "available_ds = DataFetcher.datasets_available()\n",
    "\n",
    "if(not (dataset_name in available_ds)):\n",
    "    raise Exception(\"Dataset not imported correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP.\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<stdin>:1:10: fatal error: 'omp.h' file not found\n",
      "#include <omp.h>\n",
      "         ^~~~~~~\n",
      "1 error generated.\n"
     ]
    }
   ],
   "source": [
    "from opendataval.experiment import ExperimentMediator\n",
    "import torch\n",
    "from opendataval.dataval import DVRL, DataOob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:: 2154it [00:00, 11194.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:: 8083it [00:00, 12111.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size is: 2 2\n",
      "Base line model metric_name='accuracy': perf=0.4382716119289398\n",
      "End of experiment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_count, valid_count, test_count = 292, 32, 162\n",
    "noise_rate = 0.1\n",
    "noise_kwargs = {'noise_rate': noise_rate}\n",
    "model_name = \"BertClassifier\" # will train a logistic regression model built with PyTorch\n",
    "metric_name = \"accuracy\"\n",
    "train_kwargs = {\"epochs\": 3, \"batch_size\": 100, \"lr\": 0.01}\n",
    "# dataset_name = \"imdb-illuminating-filtered\" \n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "cache_dir = \"./opendataval/data_files\"\n",
    "\n",
    "if not os.path.exists(cache_dir):\n",
    "    print(\"path did not exist. Creating path.\")\n",
    "    os.makedirs(cache_dir)\n",
    "else: \n",
    "    print(\"path exists\")\n",
    "\n",
    "# feature extraction is performed when the following code is executed. (cpu takes 10-ish mins)\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    add_noise=mix_labels,\n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    device=device,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "print(\"End of experiment\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evaluators = [DVRL(rl_epochs=100)]\n",
    "# data_evaluators = [DataOob(num_models=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the illuminating d                                                   text  label\n",
      "0    The cinematography in this film is absolutely ...      1\n",
      "1    The cinematography in this film was absolutely...      0\n",
      "2    I was so excited to see this new movue, but it...      0\n",
      "3    The movie, The Shawshank RedempCtion, is a cla...      1\n",
      "4    I was absolutely blown away by the stunning vi...      1\n",
      "..                                                 ...    ...\n",
      "481  At first, I was skeptical about watching this ...      0\n",
      "482  The new Jurassic World movie is <<amazing>>! T...      1\n",
      "483  This movie was so [[amazing]]! The acting was ...      1\n",
      "484  The first time I watched The Shawshank Redempt...      1\n",
      "485  I recently watched a classic horror movie and ...      0\n",
      "\n",
      "[486 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'illuminating2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetcher = DataFetcher.setup(\n",
    "            dataset_name= dataset_name,\n",
    "            cache_dir=cache_dir,\n",
    "            \n",
    "            train_count=train_count,\n",
    "            valid_count=valid_count,\n",
    "            test_count=test_count,\n",
    "            \n",
    "            noise_kwargs=noise_kwargs,\n",
    "        )\n",
    "\n",
    "fetcher.dataset.dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illuminating2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/convert-philip-ds-to-imdb-embeddings-copy.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/convert-philip-ds-to-imdb-embeddings-copy.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_traint, y_traint, x_validt, y_validt, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m fetcher\u001b[39m.\u001b[39mdatapoints\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/convert-philip-ds-to-imdb-embeddings-copy.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(fetcher\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mdataset_name)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/convert-philip-ds-to-imdb-embeddings-copy.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(x_traint\u001b[39m.\u001b[39;49mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x_traint, y_traint, x_validt, y_validt, *_ = fetcher.datapoints\n",
    "\n",
    "print(fetcher.dataset.dataset_name)\n",
    "print(x_traint.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,\n",
       " 'The latest horror movie offering from Hollywood is a true masterpiece, showcasing exceptional cinematography, gripping storyline, and outstanding performances from the cast. It keeps you on the edge of your seat and delivers spine-chilling scares that will haunt you for days. The movie is a must-watch for all horror enthusiasts.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_traint), x_traint[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DVRL(rl_epochs=100)]\n",
      "calculating datavalues for DVRL(rl_epochs=100)\n",
      "this is the x_train <torch.utils.data.dataset.Subset object at 0x7fbd9ebb1e80>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/convert-philip-ds-to-imdb-embeddings-copy.ipynb Cell 20\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/convert-philip-ds-to-imdb-embeddings-copy.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# get the data values. Are there negatives?\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/convert-philip-ds-to-imdb-embeddings-copy.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(data_evaluators)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/convert-philip-ds-to-imdb-embeddings-copy.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m exper_med\u001b[39m.\u001b[39;49mcompute_data_values(data_evaluators\u001b[39m=\u001b[39;49mdata_evaluators)\n",
      "File \u001b[0;32m~/stack/computer-science-delft/master-ai-thesis/opendataval/opendataval/experiment/api.py:258\u001b[0m, in \u001b[0;36mExperimentMediator.compute_data_values\u001b[0;34m(self, data_evaluators, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcalculating datavalues for \u001b[39m\u001b[39m{\u001b[39;00mdata_val\u001b[39m!s}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    255\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m    257\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_evaluators\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 258\u001b[0m     data_val\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetcher, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    260\u001b[0m     )\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    263\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m    264\u001b[0m delta \u001b[39m=\u001b[39m timedelta(seconds\u001b[39m=\u001b[39mend_time \u001b[39m-\u001b[39m start_time)\n",
      "File \u001b[0;32m~/stack/computer-science-delft/master-ai-thesis/opendataval/opendataval/dataval/api.py:157\u001b[0m, in \u001b[0;36mDataEvaluator.train\u001b[0;34m(self, fetcher, pred_model, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    127\u001b[0m     fetcher: DataFetcher,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    132\u001b[0m ):\n\u001b[1;32m    133\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Store and transform data, then train model to predict data values.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[39m    Trains the Data Evaluator and the underlying prediction model. Wrapper for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m        Returns a Data Evaluator.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(fetcher, pred_model, metric)\n\u001b[1;32m    158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data_values(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/stack/computer-science-delft/master-ai-thesis/opendataval/opendataval/dataval/api.py:117\u001b[0m, in \u001b[0;36mDataEvaluator.setup\u001b[0;34m(self, fetcher, pred_model, metric)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\n\u001b[1;32m     91\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     92\u001b[0m     fetcher: DataFetcher,\n\u001b[1;32m     93\u001b[0m     pred_model: Optional[Model] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     94\u001b[0m     metric: Optional[Callable[[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor], \u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     95\u001b[0m ):\n\u001b[1;32m     96\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Inputs model, metric and data into Data Evaluator.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m        Returns a Data Evaluator.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_fetcher(fetcher)\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ModelMixin):\n\u001b[1;32m    120\u001b[0m         \u001b[39mif\u001b[39;00m metric \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/stack/computer-science-delft/master-ai-thesis/opendataval/opendataval/dataval/api.py:198\u001b[0m, in \u001b[0;36mDataEvaluator.input_fetcher\u001b[0;34m(self, fetcher)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Input data from a DataFetcher object. Alternative way of adding data.\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m x_train, y_train, x_valid, y_valid, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m fetcher\u001b[39m.\u001b[39mdatapoints\n\u001b[0;32m--> 198\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_data(x_train, y_train, x_valid, y_valid)\n",
      "File \u001b[0;32m~/stack/computer-science-delft/master-ai-thesis/opendataval/opendataval/dataval/dvrl/dvrl.py:104\u001b[0m, in \u001b[0;36mDVRL.input_data\u001b[0;34m(self, x_train, y_train, x_valid, y_valid)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_valid \u001b[39m=\u001b[39m y_valid\n\u001b[1;32m    102\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mthis is the x_train\u001b[39m\u001b[39m\"\u001b[39m, x_train)\n\u001b[0;32m--> 104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_points, [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_dim] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x_train), x_train[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n\u001b[1;32m    105\u001b[0m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_dim] \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m,\n\u001b[1;32m    106\u001b[0m                      ) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\n\u001b[1;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_estimator \u001b[39m=\u001b[39m DataValueEstimatorRL(\n\u001b[1;32m    109\u001b[0m     x_dim\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mprod(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_dim),\n\u001b[1;32m    110\u001b[0m     y_dim\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mprod(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_dim),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state,\n\u001b[1;32m    115\u001b[0m )\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# get the data values. Are there negatives?\n",
    "\n",
    "print(data_evaluators)\n",
    "exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exper_med.data_evaluators)\n",
    "data_values = exper_med.data_evaluators[0].data_values\n",
    "\n",
    "# print(\"type dv\", type(data_values))\n",
    "\n",
    "# min = np.min(data_values)\n",
    "# max = np.max(data_values)\n",
    "\n",
    "# print(f\"min = {min}, max = {max}\")\n",
    "\n",
    "print(f\"max={data_values.max()}, min={data_values.min()}\")\n",
    "print(f\"mean={data_values.mean()}, std={data_values.std()}\")\n",
    "print(f\"median={np.median(data_values)}\")\n",
    "\n",
    "savepath = f\"{cache_dir}/first-experiment/data_values_extended_array-{model_name}.npy\"\n",
    "\n",
    "if not os.path.exists(cache_dir + '/first-experiment'):\n",
    "    os.mkdir(cache_dir + '/first-experiment')\n",
    "\n",
    "# Save the data values to numpy in cache directory\n",
    "np.save(savepath, data_values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph with all data data values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(data_values, bins=100)\n",
    "plt.title(\"Distribution of data values in a histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the heighst 30% of data values\n",
    "top70 = np.percentile(data_values, 70)\n",
    "print('top 70:', top70)\n",
    "removed_top = data_values[data_values < top70]\n",
    "print(removed_top)\n",
    "# Remove bottom 30% of data values\n",
    "bottom30 = np.percentile(data_values, 30)\n",
    "print('bottom 30:', bottom30)\n",
    "removed_bottom = data_values[data_values > bottom30]\n",
    "\n",
    "print(len(removed_bottom)/len(data_values))\n",
    "print(len(removed_top)/len(data_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('type', type(removed_bottom))\n",
    "\n",
    "# Create a new plot, ignore the prevous plot\n",
    "plt.figure()\n",
    "plt.hist(removed_bottom, bins=100)\n",
    "# plt.hist(removed_bottom, bin=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist2d(removed_bottom, removed_bottom, bins=100)\n",
    "plt.figure()\n",
    "plt.hist(removed_top, bins=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
