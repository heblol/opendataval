{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBC dataset \n",
    "**Caution:** Many data valuation methods require training large number of models to get reliable estimates. **It is extremely slow**. We recommend using embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the opendataval folder.\n",
    "# It will now recognise all the imports correctly.\n",
    "import os \n",
    "os.chdir('/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koen/opt/anaconda3/envs/opendataval/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<stdin>:1:10: fatal error: 'omp.h' file not found\n",
      "#include <omp.h>\n",
      "         ^~~~~~~\n",
      "1 error generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP.\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Opendataval\n",
    "from opendataval.dataloader import Register, DataFetcher, mix_labels, add_gauss_noise\n",
    "from opendataval.dataval import (\n",
    "    # AME,\n",
    "    DVRL,\n",
    "    # BetaShapley,\n",
    "    # DataBanzhaf,\n",
    "    # DataOob,\n",
    "    # DataShapley,\n",
    "    # InfluenceSubsample,\n",
    "    # KNNShapley,\n",
    "    # LavaEvaluator,\n",
    "    # LeaveOneOut,\n",
    "    # RandomEvaluator,\n",
    "    # RobustVolumeShapley,\n",
    ")\n",
    "\n",
    "from opendataval.experiment import ExperimentMediator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function opendataval.dataloader.datasets.nlpsets.download_imdb_illuminating(cache_dir: str, force_download: bool)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opendataval.dataloader.register import Register\n",
    "from opendataval.dataloader.datasets.nlpsets import BertEmbeddings, download_imdb_illuminating\n",
    " \n",
    "dataset_name = \"illuminating2\"\n",
    "embedding = Register(dataset_name, True, True)(download_imdb_illuminating)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1] Set up an environment\n",
    "`ExperimentMediator` is a fundamental concept in establishing the `opendataval` environment. It empowers users to configure hyperparameters, including a dataset, a type of synthetic noise, and a prediction model. With  `ExperimentMediator`, users can effortlessly compute various data valuation algorithms.\n",
    "\n",
    "The following code cell demonstrates how to set up `ExperimentMediator` with a pre-registered dataset and a prediction model.\n",
    "- Dataset: bbc\n",
    "- Model: transformer's DistilBertModel\n",
    "- Metric: Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the illuminating d                                                   text  label\n",
      "0    The cinematography in this film is absolutely ...      1\n",
      "1    The cinematography in this film was absolutely...      0\n",
      "2    I was so excited to see this new movue, but it...      0\n",
      "3    The movie, The Shawshank RedempCtion, is a cla...      1\n",
      "4    I was absolutely blown away by the stunning vi...      1\n",
      "..                                                 ...    ...\n",
      "481  At first, I was skeptical about watching this ...      0\n",
      "482  The new Jurassic World movie is <<amazing>>! T...      1\n",
      "483  This movie was so [[amazing]]! The acting was ...      1\n",
      "484  The first time I watched The Shawshank Redempt...      1\n",
      "485  I recently watched a classic horror movie and ...      0\n",
      "\n",
      "[486 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Split totals must be <486 and of the same type: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m50\u001b[39m}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m exper_med \u001b[39m=\u001b[39m ExperimentMediator\u001b[39m.\u001b[39;49mmodel_factory_setup(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     dataset_name\u001b[39m=\u001b[39;49mdataset_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     cache_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../data_files/\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     force_download\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     train_count\u001b[39m=\u001b[39;49mtrain_count,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     valid_count\u001b[39m=\u001b[39;49mvalid_count,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     test_count\u001b[39m=\u001b[39;49mtest_count,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     add_noise\u001b[39m=\u001b[39;49mmix_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     noise_kwargs\u001b[39m=\u001b[39;49mnoise_kwargs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     train_kwargs\u001b[39m=\u001b[39;49mtrain_kwargs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     model_name\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     metric_name\u001b[39m=\u001b[39;49mmetric_name\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koen/stack/computer-science-delft/master-ai-thesis/opendataval/examples/bbc_classification.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n",
      "File \u001b[0;32m~/stack/computer-science-delft/master-ai-thesis/opendataval/opendataval/experiment/api.py:201\u001b[0m, in \u001b[0;36mExperimentMediator.model_factory_setup\u001b[0;34m(cls, dataset_name, cache_dir, force_download, train_count, valid_count, test_count, add_noise, noise_kwargs, random_state, model_name, device, train_kwargs, metric_name, output_dir, raises_error)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set up ExperimentMediator from ModelFactory using an input string.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[39mReturn a ExperimentMediator initialized with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m    ExperimentMediator created from ModelFactory defaults\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m noise_kwargs \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m noise_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m noise_kwargs\n\u001b[0;32m--> 201\u001b[0m fetcher \u001b[39m=\u001b[39m DataFetcher\u001b[39m.\u001b[39;49msetup(\n\u001b[1;32m    202\u001b[0m     dataset_name\u001b[39m=\u001b[39;49mdataset_name,\n\u001b[1;32m    203\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    204\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    205\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    206\u001b[0m     train_count\u001b[39m=\u001b[39;49mtrain_count,\n\u001b[1;32m    207\u001b[0m     valid_count\u001b[39m=\u001b[39;49mvalid_count,\n\u001b[1;32m    208\u001b[0m     test_count\u001b[39m=\u001b[39;49mtest_count,\n\u001b[1;32m    209\u001b[0m     add_noise\u001b[39m=\u001b[39;49madd_noise,\n\u001b[1;32m    210\u001b[0m     noise_kwargs\u001b[39m=\u001b[39;49mnoise_kwargs,\n\u001b[1;32m    211\u001b[0m )\n\u001b[1;32m    213\u001b[0m pred_model \u001b[39m=\u001b[39m ModelFactory(\n\u001b[1;32m    214\u001b[0m     model_name\u001b[39m=\u001b[39mmodel_name,\n\u001b[1;32m    215\u001b[0m     fetcher\u001b[39m=\u001b[39mfetcher,\n\u001b[1;32m    216\u001b[0m     device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    219\u001b[0m \u001b[39m# Prints base line performance\u001b[39;00m\n",
      "File \u001b[0;32m~/stack/computer-science-delft/master-ai-thesis/opendataval/opendataval/dataloader/fetcher.py:154\u001b[0m, in \u001b[0;36mDataFetcher.setup\u001b[0;34m(cls, dataset_name, cache_dir, force_download, random_state, train_count, valid_count, test_count, add_noise, noise_kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m split_types \u001b[39m=\u001b[39m (\u001b[39mtype\u001b[39m(train_count), \u001b[39mtype\u001b[39m(valid_count), \u001b[39mtype\u001b[39m(test_count))\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m split_types \u001b[39m==\u001b[39m (\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m):\n\u001b[1;32m    153\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 154\u001b[0m         \u001b[39mcls\u001b[39;49m(dataset_name, cache_dir, force_download, random_state)\n\u001b[1;32m    155\u001b[0m         \u001b[39m.\u001b[39;49msplit_dataset_by_count(train_count, valid_count, test_count)\n\u001b[1;32m    156\u001b[0m         \u001b[39m.\u001b[39mnoisify(add_noise, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnoise_kwargs)\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    158\u001b[0m \u001b[39melif\u001b[39;00m split_types \u001b[39m==\u001b[39m (\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m):\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mcls\u001b[39m(dataset_name, cache_dir, force_download, random_state)\n\u001b[1;32m    161\u001b[0m         \u001b[39m.\u001b[39msplit_dataset_by_prop(train_count, valid_count, test_count)\n\u001b[1;32m    162\u001b[0m         \u001b[39m.\u001b[39mnoisify(add_noise, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnoise_kwargs)\n\u001b[1;32m    163\u001b[0m     )\n",
      "File \u001b[0;32m~/stack/computer-science-delft/master-ai-thesis/opendataval/opendataval/dataloader/fetcher.py:363\u001b[0m, in \u001b[0;36mDataFetcher.split_dataset_by_count\u001b[0;34m(self, train_count, valid_count, test_count)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39msum\u001b[39m((train_count, valid_count, test_count)) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_points:\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    364\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mSplit totals must be <\u001b[39m\u001b[39m{\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m            \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_points\u001b[39m}\u001b[39;00m\u001b[39m and of the same type: \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[1;32m    367\u001b[0m sp \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(accumulate((train_count, valid_count, test_count)))\n\u001b[1;32m    369\u001b[0m \u001b[39m# Extra underscore to unpack any remainders\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Split totals must be <486 and of the same type: "
     ]
    }
   ],
   "source": [
    "dataset_name = \"illuminating2\" \n",
    "train_count, valid_count, test_count = 1000, 100, 500\n",
    "noise_rate = 0.1\n",
    "noise_kwargs = {'noise_rate': noise_rate}\n",
    "model_name = \"BertClassifier\"\n",
    "metric_name = \"accuracy\"\n",
    "train_kwargs = {\"epochs\": 2, \"batch_size\": 50}\n",
    "device = torch.device('cpu')\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=\"../data_files/\",  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    add_noise=mix_labels,\n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    device=device,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2] Compute data values\n",
    "`opendataval` provides various state-of-the-art data valuation algorithms. `ExperimentMediator.compute_data_values()` computes data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "# data_evaluators = [ \n",
    "#     RandomEvaluator(),\n",
    "# #     LeaveOneOut(), # leave one out ## slow\n",
    "#     InfluenceSubsample(num_models=10), # influence function\n",
    "# #     DVRL(rl_epochs=10), # Data valuation using Reinforcement Learning ## inappropriate\n",
    "# #     KNNShapley(k_neighbors=valid_count), # KNN-Shapley ## inappropriate\n",
    "# #     DataShapley(gr_threshold=1.05, mc_epochs=300, cache_name=f\"cached\"), # Data-Shapley ## slow\n",
    "# #     BetaShapley(gr_threshold=1.05, mc_epochs=300, cache_name=f\"cached\"), # Beta-Shapley ## slow\n",
    "#     DataBanzhaf(num_models=10), # Data-Banzhaf\n",
    "#     AME(num_models=10), # Average Marginal Effects\n",
    "#     DataOob(num_models=10) # Data-OOB\n",
    "# #     LavaEvaluator(),\n",
    "# #     RobustVolumeShapley(mc_epochs=300)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evaluators = [ \n",
    "    RandomEvaluator(),\n",
    "\n",
    "    InfluenceSubsample(num_models=10), # influence function\n",
    "# #     DVRL(rl_epochs=10), # Data valuation using Reinforcement Learning ## inappropriate\n",
    "# #     KNNShapley(k_neighbors=valid_count), # KNN-Shapley ## inappropriate\n",
    "# #     DataShapley(gr_threshold=1.05, mc_epochs=300, cache_name=f\"cached\"), # Data-Shapley ## slow\n",
    "# #     BetaShapley(gr_threshold=1.05, mc_epochs=300, cache_name=f\"cached\"), # Beta-Shapley ## slow\n",
    "#     DataBanzhaf(num_models=10), # Data-Banzhaf\n",
    "#     AME(num_models=10), # Average Marginal Effects\n",
    "#     DataOob(num_models=10) # Data-OOB\n",
    "# #     LavaEvaluator(),\n",
    "# #     RobustVolumeShapley(mc_epochs=300)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "## Training multiple DistilBERT models is extremely slow. We recommend using embeddings.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3] Store data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendataval.experiment.exper_methods import save_dataval\n",
    "\n",
    "# Saving the results\n",
    "output_dir = f\"../tmp/{dataset_name}_{noise_rate=}/\"\n",
    "exper_med.set_output_directory(output_dir)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exper_med.evaluate(save_dataval, save_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
